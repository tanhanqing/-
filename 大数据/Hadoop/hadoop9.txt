链式job编程
--------------
	MR		//Mapper+ / Reduce Mapper*

DBWritable
---------------
	和数据库交互。

Sqoop
----------------
	
全排序
------------------
	对reduce输出的所有结果进行排序。


二次排序
-------------------
	对value进行排序。

数据倾斜
-------------------
	1.reduce
	2.自定义分区函数
		数据结果错 + 二次job
	3.重新设计key
		数据结果错 + 二次job


网络拓扑结构
------------------
	

机架感知
-------------------
s202--192.168.231.202		/rack1/202
s203--192.168.231.203		/rack1/203
s204--192.168.231.204		/rack2/204
s205--192.168.231.205		/rack2/205


fault tolerance
-----------------
	容错.
	业务。


fail over
----------------
	容灾.
	硬件故障。
	

master / slave
---------------
	主(master,namenode)从(slave,datanode)结构.

 topology.node.switch.mapping.impl


可靠性
---------------
	提供数据安全的能力。

可用性
---------------
	提供持续服务的能力。

默认的副本放置策略
--------------------
	首选在本地机架的一个node存放副本,另一个副本在本地机架的另一个不同节点。
	最后一个副本在不同机架的不同节点上。

hads oiv		//image data metadata.
hads oev		//edit



自定义机架感知(优化hadoop集群一种方式)
--------------------
	1.自定义实现类
		package com.it18zhang.hdfs.rackaware;

		import org.apache.hadoop.net.DNSToSwitchMapping;

		import java.util.ArrayList;
		import java.util.List;

		/**
		 *机架感知类
		 */
		public class MyRackAware implements DNSToSwitchMapping {

			public List<String> resolve(List<String> names) {
				List<String> list =  new ArrayList<String>();
				for(String str : names){
					//输出原来的信息,ip地址(主机名)
					System.out.println(str);
					//
					if(str.startsWith("192")){
						//192.168.231.202
						String ip = str.substring(str.lastIndexOf(".") + 1);
						if(Integer.parseInt(ip) <= 203) {
							list.add("/rack1/" + ip);
						}
						else{
							list.add("/rack2/" + ip);
						}
					}
					else if(str.startsWith("s")){
						String ip = str.substring(1);
						if (Integer.parseInt(ip) <= 203) {
							list.add("/rack1/" + ip);
						} else {
							list.add("/rack2/" + ip);
						}
					}
				}
				return list;
			}

			public void reloadCachedMappings() {

			}

			public void reloadCachedMappings(List<String> names) {
			}
		}


	2.配置core-site.xml
		<?xml version="1.0" encoding="UTF-8"?>
		<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
		<configuration>
				<property>
						<name>fs.defaultFS</name>
						<value>hdfs://192.168.231.201/</value>
				</property>
				<property>
						<name>hadoop.tmp.dir</name>
						<value>/home/centos/hadoop</value>
				</property>
				<property>
						<name>topology.node.switch.mapping.impl</name>
						<value>com.it18zhang.hdfs.rackaware.MyRackAware</value>
				</property>
		</configuration>

	3.导出jar包
	
	4.复制jar到/soft/hadoop/shared/hadoop/common/lib
		
	5.分发jar.(可以不做)
		实际上不需要分发，只在名称节点上运行。

	6.重启名称节点
		$>hadoop-daemon.sh stop namenode
		$>hadoop-daemon.sh start namenode

去IOE
-----------
	IBM			//
	Oracle		//
	EMC			//

HA
--------------
	1.NFS
		网络共享存储设备。

	2.QJM
		Quorum Journal Manager

	3.两个名称节点
		active			//激活
		standby			//待命


active			//激活
deactive		//钝化

SPOF
----------------
	single point of failure,单点故障。

事务是个特性
--------------
	a		//atomic	原子性
	c		//consistent一致性
	i		//isolate	隔离型
	d		//durable	永久性·


majority 
------------
	大部分.


HA高可用配置
-------------------
	high availability,高可用.
	/home/centos/hadoop/dfs/data/current/BP-2100834435-192.168.231.201-1489328949370/current/finalized/subdir0/subdir0

	两个名称节点，一个active(激活态)，一个是standby(slave待命),slave节点维护足够多状态以便于容灾。
	和客户端交互的active节点,standby不交互.
	两个节点都和JN守护进程构成组的进行通信。

	数据节点配置两个名称节点，分别报告各自的信息。

	同一时刻只能有一个激活态名称节点。

	脑裂:两个节点都是激活态。
	为防止脑裂，JNs只允许同一时刻只有一个节点向其写数据。容灾发生时，成为active节点的namenode接管
	向jn的写入工作。



硬件资源
--------------
	名称节点:	硬件配置相同。
	JN节点	:	轻量级进程，至少3个节点,允许挂掉的节点数 (n - 1) / 2.
				不需要再运行辅助名称节点。

部署
----------------


配置细节
---------------
	0.s201和s206具有完全一致的配置，尤其是ssh.

	1.配置nameservice
		[hdfs-site.xml]
		<property>
			<name>dfs.nameservices</name>
			<value>mycluster</value>
		</property>
		
	2.dfs.ha.namenodes.[nameservice ID]
		[hdfs-site.xml]
		<!-- myucluster下的名称节点两个id -->
		<property>
			<name>dfs.ha.namenodes.mycluster</name>
			<value>nn1,nn2</value>
		</property>

	3.dfs.namenode.rpc-address.[nameservice ID].[name node ID] 
		[hdfs-site.xml]
		配置每个nn的rpc地址。
		<property>
			<name>dfs.namenode.rpc-address.mycluster.nn1</name>
			<value>s201:8020</value>
		</property>
		<property>
			<name>dfs.namenode.rpc-address.mycluster.nn2</name>
			<value>s206:8020</value>
		</property>
	
	4.dfs.namenode.http-address.[nameservice ID].[name node ID]
		配置webui端口
		[hdfs-site.xml]
		<property>
			<name>dfs.namenode.http-address.mycluster.nn1</name>
			<value>s201:50070</value>
		</property>
		<property>
			<name>dfs.namenode.http-address.mycluster.nn2</name>
			<value>s206:50070</value>
		</property>

	5.dfs.namenode.shared.edits.dir
		名称节点共享编辑目录.
		[hdfs-site.xml]
		<property>
			<name>dfs.namenode.shared.edits.dir</name>
			<value>qjournal://s202:8485;s203:8485;s204:8485/mycluster</value>
		</property>

	6.dfs.client.failover.proxy.provider.[nameservice ID]
		java类，client使用它判断哪个节点是激活态。
		[hdfs-site.xml]
		<property>
			<name>dfs.client.failover.proxy.provider.mycluster</name>
			<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
		</property>
	
	7.dfs.ha.fencing.methods
		脚本列表或者java类，在容灾保护激活态的nn.
		[hdfs-site.xml]
		<property>
			<name>dfs.ha.fencing.methods</name>
			<value>
					sshfence
					shell(/bin/true)
			</value>
		</property>

		<property>
			<name>dfs.ha.fencing.ssh.private-key-files</name>
			<value>/home/centos/.ssh/id_rsa</value>
		</property>

	8.fs.defaultFS 
		配置hdfs文件系统名称服务。
		[core-site.xml]
		<property>
			<name>fs.defaultFS</name>
			<value>hdfs://mycluster</value>
		</property>
	
	9.dfs.journalnode.edits.dir
		配置JN存放edit的本地路径。
		[hdfs-site.xml]
		<property>
			<name>dfs.journalnode.edits.dir</name>
			<value>/home/centos/hadoop/journal</value>
		</property>

部署细节
----------------
	1.在jn节点分别启动jn进程
		$>hadoop-daemon.sh start journalnode

	2.启动jn之后，在两个NN之间进行disk元数据同步
		a)如果是全新集群，先format文件系统,只需要在一个nn上执行。
			[s201]
			$>hadoop namenode -format
		
		b)如果将非HA集群转换成HA集群，复制原NN的metadata到另一个nn.
			1.步骤一
				[s201]
				$>scp -r /home/centos/hadoop/dfs centos@s206:/home/centos/hadoop/

			2.步骤二
				在新的nn(未格式化的nn)上运行一下命令，实现待命状态引导。
				[s206]
				$>hdfs namenode -bootstrapStandby		//需要s201为启动状态,提示是否格式化,选择N.
				
			3)在一个NN上执行以下命令，完成edit日志到jn节点的传输。（thq测试在s206有效，s201报错）
				$>hdfs namenode -initializeSharedEdits
				#查看s202,s203是否有edit数据.

			4)启动所有节点.
				[s201]
				$>hadoop-daemon.sh start namenode		//启动名称节点
				$>hadoop-daemons.sh start datanode		//启动所有数据节点

				[s206]
				$>hadoop-daemon.sh start namenode		//启动名称节点
			

HA管理
-----------------
	$>hdfs haadmin -transitionToActive nn1				//切成激活态
	$>hdfs haadmin -transitionToStandby nn1				//切成待命态
	$>hdfs haadmin -transitionToActive --forceactive nn2//强行激活
	$>hdfs haadmin -failover nn1 nn2					//模拟容灾演示,从nn1切换到nn2

