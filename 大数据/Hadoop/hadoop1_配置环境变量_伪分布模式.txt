hadoop
----------------
	开源软件，可靠的、分布式、可伸缩的。


大数据
----------------
	

去IOE
-------------
	IBM			//ibm小型机.
	Oracle		//oracle数据库服务器 RAC
	EMC			//EMC共享存储设备。

Cluster
----------------
	集群。

1T = 1024G
1P = 1024T
1E = 1024P
1Z = 1024E
1Y = 1024Z
1N = 1024Y

海量数据
---------------
	PB.


RAID
--------------
	磁盘阵列。
	

大数据解决了两个问题
----------------------
	1.存储
		分布式存储
	2.计算
		分布式计算
分布式
----------------------
	由分布在不同主机上的进程协同在一起，才能构成整个应用。

B/S
-----------
	Browser / http server:瘦客户端.

failure over		//容灾
fault over			//容错


云计算
-------------
	1.服务。
	3.虚拟化.

大数据的四个V特征
-----------------
	1.volume	//体量大
	2.variety	//样式多.
	3.velocity	//速度快
	4.valueless	//价值密度低


hadoop四个模块
-------------------	
	1.common
	2.hdfs 
	3.hadoop yarn
	4.hadooop mapreduce(mr)

安装hadoop
-------------------
	1.安装jdk
		a)下载jdk-8u65-linux-x64.tar.gz
		b)tar开
			$>su centos ; cd ~
			$>mkdir downloads
			$>cp /mnt/hdfs/downloads/bigdata/jdk-8u65-linux-x64.tar.gz ~/downlooads
			$>tar -xzvf jdk-8u65-linux-x64.tar.gz
		c)创建/soft文件夹
			$>sudo mkdir /soft
			$>sudo chown centos:centos /soft
		d)移动tar开的文件到/soft下
			$>mv ~/downloads/jdk-1.8.0_65 /soft/
		e)创建符号连接
			$>ln -s /soft/jdk-1.8.0_65 /soft/jdk
		f)验证jdk安装是否成功
			$>cd /soft/jdk/bin
			$>./java -version

centos配置环境变量
------------------------
	1.编辑/etc/profile
		$>sudo nano /etc/profile
		...
		export JAVA_HOME=/soft/jdk
		exprot PATH=$PATH:$JAVA_HOME/bin
	2.使环境变量即刻生效
		$>source /etc/profile
	
	3.进入任意目录下,测试是否ok
		$>cd ~
		$>java -version

安装hadoop
-------------------------
	1.安装hadoop
		a)下载hadoop-2.7.3.tar.gz
		b)tar开
			$>su centos ; cd ~
			$>cp /mnt/hdfs/downloads/bigdata/hadoop-2.7.3.tar.gz ~/downloads
			$>tar -xzvf hadoop-2.7.3.tar.gz
		c)无
		d)移动tar开的文件到/soft下
			$>mv ~/downloads/hadoop-2.7.3 /soft/
		e)创建符号连接
			$>ln -s /soft/hadoop-2.7.3 /soft/hadoop
		f)验证jdk安装是否成功
			$>cd /soft/hadoop/bin
			$>./hadoop version
	
	2.配置hadoop环境变量
		$>sudo nano /etc/profile
		...
		export JAVA_HOME=/soft/jdk
		exprot PATH=$PATH:$JAVA_HOME/bin

		export HADOOP_HOME=/soft/hadoop
		export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
	
	3.生效
		$>source /etc/profile

配置hadoop
--------------------
	1.standalone(local)
		nothing !
		不需要启用单独的hadoop进程。
	
	2.Pseudodistributed mode
		伪分布模式。
		a)进入${HADOOP_HOME}/etc/hadoop目录
		b)编辑core-site.xml
			<?xml version="1.0"?>
			<configuration>
				<property>
					<name>fs.defaultFS</name>
					<value>hdfs://localhost/</value>
				</property>
			</configuration>
		c)编辑hdfs-site.xml
			<?xml version="1.0"?>
			<configuration>
				<property>
					<name>dfs.replication</name>
					<value>1</value>
				</property>
			</configuration>
		d)编辑mapred-site.xml
			注意:cp mapred-site.xml.template mapred-site.xml
			<?xml version="1.0"?>
			<configuration>
				<property>
					<name>mapreduce.framework.name</name>
					<value>yarn</value>
				</property>
			</configuration>
		e)编辑yarn-site.xml
			<?xml version="1.0"?>
			<configuration>
				<property>
					<name>yarn.resourcemanager.hostname</name>
					<value>localhost</value>
				</property>
				<property>
					<name>yarn.nodemanager.aux-services</name>
					<value>mapreduce_shuffle</value>
				</property>
			</configuration>

		f)配置SSH
			1)检查是否安装了ssh相关软件包(openssh-server + openssh-clients + openssh)
				$yum list installed | grep ssh

			2)检查是否启动了sshd进程
				$>ps -Af | grep sshd
			
			3)在client侧生成公私秘钥对。
				$>ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
			
			4)生成~/.ssh文件夹，里面有id_rsa(私钥) + id_rsa.pub(公钥)

			5)追加公钥到~/.ssh/authorized_keys文件中(文件名、位置固定)
				$>cd ~/.ssh
				$>cat id_rsa.pub >> authorized_keys
			
			6)修改authorized_keys的权限为644.
				$>chmod 644 authorized_keys
			
			7)测试
				$>ssh localhost
				